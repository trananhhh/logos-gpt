# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.1.4

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
# interface:
# Privacy policy settings
# privacyPolicy:
#   externalUrl: 'https://librechat.ai/privacy-policy'
#   openNewTab: true

# Terms of service
# termsOfService:
#   externalUrl: 'https://librechat.ai/tos'
#   openNewTab: true

# Example Registration Object Structure (optional)
# registration:
# socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']
# allowedDomains:
# - "gmail.com"
# tts:
#   url: ''
#   apiKey: '${TTS_API_KEY}'
#   model: ''
#   backend: ''
#   voice: ''
#   compatibility: ''
#   voice_settings:
#     similarity_boost: ''
#     stability: ''
#     style: ''
#     use_speaker_boost:
#   pronunciation_dictionary_locators: ['']
#
speech:
  stt:
    #   url: ''
    apiKey: '${STT_API_KEY}'
    model: 'whisper-1'

# rateLimits:
#   fileUploads:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for file uploads per user
#   conversationsImport:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user

interface:
  endpointsMenu: false
  modelSelect: false
  parameters: true
  presets: false
# sidePanel: false

modelSpecs:
  enforce: false
  prioritize: true
  list:
    # BingAI
    # - name: 'copilot-sydney'
    #   iconURL: 'bingAI'
    #   label: 'Copilot Sydney'
    #   description: 'AI with internet access.'
    #   default: false
    #   preset:
    #     endpoint: 'bingAI'
    #     model: 'Sydney'
    #     # temperature: 0.7
    #     modelLabel: 'Copilot Sydney'
    #     greeting: |
    #       AI with internet access.

    # - name: 'copilot-bingAI'
    #   iconURL: 'bingAI'
    #   label: 'Copilot BingAI'
    #   description: 'AI with internet access.'
    #   default: false
    #   preset:
    #     endpoint: 'bingAI'
    #     model: 'BingAI'
    #     # temperature: 0.7
    #     modelLabel: 'Copilot BingAI'
    #     greeting: |
    #       AI with internet access.

    # GPT
    - name: 'gpt-god-3-5'
      iconURL: 'openAI'
      label: 'GPT 3.5 Turbo'
      description: 'Great for daily tasks.'
      default: true
      preset:
        iconURL: 'openAI'
        default: true
        endpoint: 'gpt-god-open-ai'
        model: 'gpt-3.5-turbo-16k'
        # temperature: 0.7
        modelLabel: 'GPT 3.5 Turbo'
        greeting: |
          Great for daily tasks.

    - name: 'gpt-god-4o'
      iconURL: 'openAI'
      label: 'GPT 4o'
      description: 'Newest and most advanced GPT model.'
      default: false
      preset:
        iconURL: 'openAI'
        endpoint: 'gpt-god-open-ai'
        model: 'gpt-4o-all'
        # temperature: 0.7
        modelLabel: 'GPT 4o'
        greeting: |
          Latest GPT model, AI with internet access.

    # Gemini
    - name: 'gemini-flash'
      default: false
      iconURL: 'google'
      label: 'Gemini 1.5 Flash'
      description: 'AI model can handle various tasks quickly, flexibly, and supports image recognition'
      preset:
        iconURL: 'google'
        default: false
        endpoint: 'google'
        model: 'gemini-1.5-flash-latest'
        # temperature: 0.7
        modelLabel: 'Gemini 1.5 Flash'
        greeting: |
          Google's advanced AI model can handle various tasks quickly, flexibly, and supports image recognition

    - name: 'gemini-pro'
      iconURL: 'google'
      label: 'Gemini 1.5 Pro'
      description: "Google's advanced AI model"
      preset:
        iconURL: 'google'
        default: false
        endpoint: 'google'
        model: 'gemini-1.5-pro-latest'
        # temperature: 0.7
        modelLabel: 'Gemini 1.5 Pro'
        greeting: |
          Google's advanced AI model

    # ClaudeAI

    # - name: 'claude-3-sonnet-unify'
    #   label: 'Claude 3 Sonnet'
    #   description: 'Featuring state-of-the-art language processing technology'
    #   preset:
    #     default: false
    #     endpoint: 'unify'
    #     model: 'claude-3-sonnet@anthropic' #'claude-3-sonnet-20240229' 'claude-3-sonnet@anthropic'
    #     # temperature: 0.7
    #     modelLabel: 'Claude 3 Sonnet'
    #     greeting: |
    #       Featuring state-of-the-art language processing technology

    # - name: 'claude-3-sonnet'
    # label: 'Claude 3 Sonnet'
    # description: 'Featuring state-of-the-art language processing technology'
    # preset:
    #   default: false
    #   endpoint: 'gpt-god-anthropic'
    #   model: 'claude-3-sonnet-20240229' #'claude-3-sonnet-20240229' 'claude-3-sonnet@anthropic'
    #   # temperature: 0.7
    #   modelLabel: 'Claude 3 Sonnet'
    #   greeting: |
    #     Featuring state-of-the-art language processing technology

    - name: 'claude-3-haiku'
      label: 'Claude 3 Haiku'
      description: 'Featuring state-of-the-art language processing technology'
      preset:
        default: false
        endpoint: 'gpt-god-anthropic'
        model: 'claude-3-haiku-20240307' #'claude-3-haiku@anthropic'
        # temperature: 0.7
        modelLabel: 'Claude 3 Haiku'
        greeting: |
          Featuring state-of-the-art language processing technology

    - name: 'claude-3-opus'
      label: 'Claude 3 Opus'
      description: 'Featuring state-of-the-art language processing technology'
      preset:
        default: false
        endpoint: 'gpt-god-anthropic'
        model: 'claude-3-opus-20240229' #'claude-3-opus@anthropic'
        # temperature: 0.7
        modelLabel: 'Claude 3 Opus'
        greeting: |
          Featuring state-of-the-art language processing technology

    - name: 'claude-3-5-sonnet'
      label: 'Claude 3.5 Sonnet'
      description: 'The latest version of the Claude model is more powerful, with the most advanced language processing technology'
      preset:
        default: false
        endpoint: 'gpt-god-anthropic'
        model: 'claude-3-5-sonnet-20240620' #'claude-3-5-sonnet@anthropic'
        # temperature: 0.7
        modelLabel: 'Claude 3.5 Sonnet'
        greeting: |
          The latest version of the Claude model is more powerful, with the most advanced language processing technology

    # Dall-E
    - name: 'gpt-dall-e-4o'
      label: 'DALL-E 3 / Image generator with GPT 4'
      description: 'Generate images starting form text.'
      preset:
        default: false
        endpoint: 'gpt-god-dall-e'
        tools: ['dalle']
        model: 'gpt-4-dalle'
        # temperature: 0.5
        modelLabel: 'DALL-E 3'
        greeting: |
          Try to be accurate while describing your image and remember that each generation is independent.

    # - name: 'gpt-dall-e-3'
    #   label: 'DALL-E 3 / Image generator'
    #   description: 'Generate images starting form text.'
    #   preset:
    #     default: false
    #     endpoint: 'gpt-god-dall-e'
    #     tools: ['dalle']
    #     model: 'dall-e-3'
    #     # temperature: 0.5
    #     modelLabel: 'DALL-E 3'
    #     greeting: |
    #       Try to be accurate while describing your image and remember that each generation is independent.

    # GPT with internet
    - name: 'gpt-god-3-5-net'
      iconURL: 'openAI'
      label: 'GPT 3.5 Turbo Internet'
      description: 'Great for daily tasks, with internet.'
      default: false
      preset:
        iconURL: 'openAI'
        default: false
        endpoint: 'gpt-god-open-ai'
        model: 'net-gpt-3.5-turbo-16k'
        # temperature: 0.7
        modelLabel: 'GPT 3.5 Turbo Internet'
        greeting: |
          Great for daily tasks.

    - name: 'gpt-god-4o-net'
      iconURL: 'openAI'
      label: 'GPT 4o Internet'
      description: 'Newest and most advanced GPT model, with internet'
      default: false
      preset:
        iconURL: 'openAI'
        endpoint: 'gpt-god-open-ai'
        model: 'net-gpt-4o-all'
        # temperature: 0.7
        modelLabel: 'GPT 4o Internet'
        greeting: |
          Latest GPT model, AI with internet access.

    # - name: 'gpt-dall-e'
    #   label: 'DALL-E / Image generator'
    #   description: 'Generate images starting form text.'
    #   preset:
    #     default: false
    #     endpoint: 'gptPlugins'
    #     tools: ['dalle']
    #     model: 'gpt-3.5-turbo'
    # temperature: 0.5
    #     modelLabel: 'AI'
    #     greeting: |
    #       Try to be accurate while describing your image and remember that each generation is independent.

# Definition of custom endpoints
endpoints:
  # assistants:
  # disableBuilder: true # Disable Assistants Builder Interface by setting to `true`
  # pollIntervalMs: 3000  # Polling interval for checking assistant updates
  # timeoutMs: 180000  # Timeout for assistant operations
  #   # Should only be one or the other, either `supportedIds` or `excludedIds`
  # supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
  #   # excludedIds: ["asst_excludedAssistantId"]
  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).
  # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`
  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature
  # retrievalModels: ["gpt-4-turbo"]
  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  # capabilities: ["code_interpreter", "retrieval", "actions", "tools", "image_vision"]
  custom:
    - name: 'unify'
      apiKey: '${CLAUDE_API_KEY}'
      iconURL: 'anthropic'
      baseURL: 'https://api.unify.ai/v1/'
      models:
        default:
          [
            'claude-3-sonnet@anthropic',
            'claude-3.5-sonnet@anthropic',
            'claude-3-haiku@anthropic',
            'claude-3-opus@anthropic',
          ]
        fetch: false
      titleConvo: true
      titleModel: 'claude-3-sonnet@anthropic'
      modelDisplayLabel: 'ClaudeAI'
      dropParams:
        - 'stop'
        - 'user'
        - 'frequency_penalty'
        - 'presence_penalty'
      titleMessageRole: 'user' # <-----------NEW
      # directEndpoint: true # <---------------NEW

    - name: 'gpt-god-open-ai'
      apiKey: '${GPTGOD_API_KEY}'
      iconURL: 'openAI'
      baseURL: 'https://api.gptgod.online/v1/'
      models:
        default: ['gpt-3.5-turbo-16k', 'net-gpt-3.5-turbo-16k', 'gpt-4o-all', 'net-gpt-4o-all']
        fetch: false
      titleConvo: true
      titleModel: 'gpt-3.5-turbo-16k'
      modelDisplayLabel: 'ChatGPT'
      titleMessageRole: 'user' # <-----------NEW

    - name: 'gpt-god-dall-e'
      apiKey: '${GPTGOD_API_KEY}'
      iconURL: 'openAI'
      baseURL: 'https://api.gptgod.online/v1/'
      models:
        default: ['gpt-3.5-turbo-16k', 'gpt-4-dalle', 'dall-e-3']
        fetch: false
      titleConvo: true
      titleModel: 'gpt-3.5-turbo-16k'
      modelDisplayLabel: 'DALL-E'
      titleMessageRole: 'user' # <-----------NEW

    - name: 'gpt-god-google'
      apiKey: '${GPTGOD_API_KEY}'
      iconURL: 'google'
      baseURL: 'https://api.gptgod.online/v1/'
      models:
        default: ['gemini-1.5-flash', 'gemini-pro-vision', 'gemini-1.5-pro', 'gpt-3.5-turbo-16k']
        fetch: false
      titleConvo: true
      titleModel: 'gpt-3.5-turbo-16k'
      modelDisplayLabel: 'Gemini'
      titleMessageRole: 'user' # <-----------NEW

    - name: 'gpt-god-anthropic'
      apiKey: '${GPTGOD_API_KEY}'
      iconURL: 'anthropic'
      baseURL: 'https://api.gptgod.online/v1/'
      models:
        default:
          [
            'claude-3-haiku-20240307',
            'claude-3-sonnet-20240229',
            'claude-3-opus-20240229',
            'claude-3-5-sonnet-20240620',
            'gpt-3.5-turbo-16k'
          ]
        fetch: false
      titleConvo: true
      titleModel: 'gpt-3.5-turbo-16k'
      modelDisplayLabel: 'ClaudeAI'
      titleMessageRole: 'user' # <-----------NEW
    # directEndpoint: true # <---------------NEW
# Mistral AI Example
# - name: 'Mistral' # Unique name for the endpoint
#   # For `apiKey` and `baseURL`, you can use environment variables that you define.
#   # recommended environment variables:
#   apiKey: '${MISTRAL_API_KEY}'
#   baseURL: 'https://api.mistral.ai/v1'

#   # Models configuration
#   models:
#     # List of default models to use. At least one value is required.
#     default: ['mistral-tiny', 'mistral-small', 'mistral-medium']
#     # Fetch option: Set to true to fetch models from API.
#     fetch: true # Defaults to false.

#   # Optional configurations

#   # Title Conversation setting
#   titleConvo: true # Set to true to enable title conversation

#   # Title Method: Choose between "completion" or "functions".
#   # titleMethod: "completion"  # Defaults to "completion" if omitted.

#   # Title Model: Specify the model to use for titles.
#   titleModel: 'mistral-tiny' # Defaults to "gpt-3.5-turbo" if omitted.

#   # Summarize setting: Set to true to enable summarization.
#   # summarize: false

#   # Summary Model: Specify the model to use if summarization is enabled.
#   # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.

#   # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
#   # forcePrompt: false

#   # The label displayed for the AI model in messages.
#   modelDisplayLabel: 'Mistral' # Default is "AI" when not set.

#   # Add additional parameters to the request. Default params will be overwritten.
#   # addParams:
#   # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/

#   # Drop Default params parameters from the request. See default params in guide linked below.
#   # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
#   dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']

# OpenRouter Example
# - name: 'OpenRouter'
# For `apiKey` and `baseURL`, you can use environment variables that you define.
# recommended environment variables:
# Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.
# apiKey: '${OPENROUTER_KEY}'
# baseURL: 'https://openrouter.ai/api/v1'
# models:
#   default: ['openai/gpt-3.5-turbo']
#   fetch: true
# titleConvo: true
# titleModel: 'GPT 3.5'
# Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.
# dropParams: ['stop']
# modelDisplayLabel: 'OpenRouter'
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
# See the Custom Configuration Guide for more information on Assistants Config:
# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint
